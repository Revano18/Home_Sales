This project uses PySpark SQL to analyze a large home sales dataset by running SQL queries on a Spark DataFrame. The goal is to extract key metrics, such as average home prices based on various conditions, and improve performance using caching and partitioning. You'll read the data from a CSV file, create temporary views, and compare query runtimes with and without optimizations. The project uses Python, PySpark, and Jupyter Notebook, and is part of Module 22 in the Data Science curriculum.
